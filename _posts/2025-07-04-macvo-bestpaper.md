---
layout: post
title:  "MAC-VO won ICRA 2025 Best Conference Paper Award!"
date:   2025-07-04 10:44:07
categories: highlights
author: "Yuheng Qiu"
published: true
sidebar:  false
permalink: /highlight-macvo-bestpaper/
image: /img/posts/2025-07-04-macvo-bestpaper/bestconference.jpg
# hero_image: /img/posts/2025-04-10-rayfronts/rayfronts-teaser.gif
---

We are thrilled to announce that our paper **"[MAC-VO](https://mac-vo.github.io/): Metrics-aware Covariance for Learning-based Stereo Visual Odometry"** has won the **ICRA 2025 Best Conference Paper Award** and **Best Paper Award on Robot Perception**! 

This prestigious recognition at the IEEE International Conference on Robotics and Automation (ICRA) 2025 highlights the significant impact of our work in advancing stereo visual odometry through learning-based approaches. The dual awards underscore both the technical excellence and practical relevance of our research in the robotics community.


<table>
  <tr>
    <td>
      <img src="/img/posts/2025-07-04-macvo-bestpaper/bestconference.jpg" width="100%"><br>
      Best Conference Paper Award
    </td>
    <td>
      <img src="/img/posts/2025-07-04-macvo-bestpaper/bestperception.jpg" width="100%"><br>
      Best Paper Award on Robot Perception
    </td>
  </tr>
</table>


## About MAC-VO

MAC-VO introduces a novel metrics-aware covariance framework that significantly improves the accuracy and reliability of learning-based stereo visual odometry systems. Our model leverages learned uncertainty to filter out low-quality features, enhance keypoint selection, and thereby improve pose estimation accuracy. MAC-VO also enables dense mapping using only stereo input, without requiring bundle adjustment or multi-frame optimization. Our approach addresses key challenges in uncertainty quantification and performance optimization for autonomous navigation applications.

We conducted extensive evaluations on public benchmark datasets, such as VBR, EuRoC, and TartanAir, and our own collection, encompassing a wide range of environments, including indoor, outdoor, and scenarios with extreme lightining conditions. These tests demonstrate that MAC-VO outperforms existing visual odometry algorithms and even some SLAM systems in difficult scenarios.

More details and open-source code can be found on our **[Project Website](https://mac-vo.github.io)**.


## Conference Highlights

During ICRA 2025, we had the opportunity to showcase our work through live demonstrations, engaging with researchers and industry professionals from around the world. The positive feedback and discussions further validated the importance of our contributions to the field.

Check out our live demonstrations from the conference:

- [ICRA 2025 Demo 1](https://www.linkedin.com/posts/yuheng-qiu-6bb9151b0_icra2025-activity-7329852781106712577-TGBG?utm_source=share&utm_medium=member_desktop&rcm=ACoAADFB4q8BfsD7FeZi2jCntcJlilWdCWaUqNA)
- [ICRA 2025 Demo 2](https://www.linkedin.com/posts/yuheng-qiu-6bb9151b0_icra2025-activity-7330644969084366848-BTDE?utm_source=share&utm_medium=member_desktop&rcm=ACoAADFB4q8BfsD7FeZi2jCntcJlilWdCWaUqNA)

Congratulations to all team members who contributed to this achievement! This award represents the culmination of dedicated research efforts and collaborative work across our team.

We look forward to continuing our research in visual odometry and contributing to the advancement of autonomous robotics technology.

<video src="/img/posts/2025-07-04-macvo-bestpaper/macvo_bestpaper_web.mp4" autoplay loop muted width="95%"></video>
